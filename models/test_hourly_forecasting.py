"""
Test de Forecasting Horario de Salidas de Aeronaves

Este m칩dulo implementa y prueba un sistema de forecasting horario
para predecir el n칰mero de salidas de aeronaves por hora.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
import xgboost as xgb
import warnings
warnings.filterwarnings('ignore')

from .data_loader import ATCAircraftDataLoader
from .preprocessing import AircraftDataPreprocessor
from .features import AircraftFeatureEngineer
from .config import ModelConfig


class HourlyForecastingModel:
    """
    Modelo de forecasting horario para salidas de aeronaves.

    Este modelo predice el n칰mero de salidas por hora usando datos
    hist칩ricos de salidas horarias y caracter칤sticas temporales.
    """

    def __init__(self, config: Optional[ModelConfig] = None):
        """Inicializa el modelo de forecasting horario."""
        self.config = config or ModelConfig()
        self.model = None
        self.scaler = StandardScaler()
        self.feature_engineer = AircraftFeatureEngineer(self.config)
        self.is_trained = False

    def load_hourly_data(self, filepath: str, start_date: Optional[str] = None, end_date: Optional[str] = None) -> pd.DataFrame:
        """
        Carga datos de salidas horarias desde archivo CSV.
        
        Args:
            filepath: Ruta al archivo CSV con datos horarias
            start_date: Fecha de inicio opcional (YYYY-MM-DD)
            end_date: Fecha de fin opcional (YYYY-MM-DD)

        Returns:
            DataFrame con datos procesados
        """
        print(f"Cargando datos horarias desde: {filepath}")

        # Leer CSV
        df = pd.read_csv(filepath)

        # Convertir timestamps
        df['time'] = pd.to_datetime(df['time'], utc=True)
        df['created'] = pd.to_datetime(df['created'], utc=True)

        # Convertir a hora local (Cuba)
        df['time'] = df['time'].dt.tz_convert('America/Havana')
        df['created'] = df['created'].dt.tz_convert('America/Havana')

        # Extraer componentes temporales
        df['hour'] = df['time'].dt.hour
        df['day'] = df['time'].dt.day
        df['month'] = df['time'].dt.month
        df['year'] = df['time'].dt.year
        df['day_of_week'] = df['time'].dt.dayofweek
        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

        # Filtrar por fecha si se especifica
        if start_date:
            start_dt = pd.to_datetime(start_date).date()
            df = df[df['time'].dt.date >= start_dt]
            
        if end_date:
            end_dt = pd.to_datetime(end_date).date()
            df = df[df['time'].dt.date <= end_dt]

        print(f"Datos cargados: {len(df)} registros")
        if not df.empty:
            print(f"Rango temporal: {df['time'].min()} - {df['time'].max()}")
        print(f"Aeropuertos 칰nicos: {df['adep'].nunique()}")

        return df

    def create_hourly_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Crea caracter칤sticas espec칤ficas para forecasting horario.

        Args:
            df: DataFrame con datos horarias

        Returns:
            DataFrame con caracter칤sticas adicionales
        """
        df = df.copy()

        # Caracter칤sticas temporales c칤clicas
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)

        # Caracter칤sticas de demanda por hora
        hourly_stats = df.groupby('hour')['total'].agg(['mean', 'std', 'min', 'max']).reset_index()
        hourly_stats.columns = ['hour', 'hourly_mean', 'hourly_std', 'hourly_min', 'hourly_max']

        df = df.merge(hourly_stats, on='hour', how='left')

        # Caracter칤sticas de aeropuerto
        airport_stats = df.groupby('adep')['total'].agg(['mean', 'std', 'count']).reset_index()
        airport_stats.columns = ['adep', 'airport_mean', 'airport_std', 'airport_count']

        df = df.merge(airport_stats, on='adep', how='left')

        # Caracter칤sticas de lag (valores anteriores)
        df = df.sort_values(['adep', 'time'])

        # Lag features por aeropuerto
        for lag in [1, 2, 3, 6, 12, 24]:
            df[f'total_lag_{lag}h'] = df.groupby('adep')['total'].shift(lag)

        # Rolling statistics
        for window in [3, 6, 12, 24]:
            df[f'total_rolling_mean_{window}h'] = df.groupby('adep')['total'].transform(
                lambda x: x.rolling(window=window, min_periods=1).mean()
            )
            df[f'total_rolling_std_{window}h'] = df.groupby('adep')['total'].transform(
                lambda x: x.rolling(window=window, min_periods=1).std()
            )

        # Fill NaN values
        df = df.fillna(method='bfill').fillna(method='ffill').fillna(0)

        return df

    def prepare_training_data(self, df: pd.DataFrame, target_hours_ahead: int = 1) -> Tuple[pd.DataFrame, pd.Series]:
        """
        Prepara datos para entrenamiento del modelo.

        Args:
            df: DataFrame con caracter칤sticas
            target_hours_ahead: Horas a predecir en el futuro

        Returns:
            Tuple de (X, y) para entrenamiento
        """
        # Crear target (valor futuro)
        df['target'] = df.groupby('adep')['total'].shift(-target_hours_ahead)

        # Remover filas con target NaN
        df = df.dropna(subset=['target'])

        # Seleccionar features
        feature_cols = [
            # Temporales
            'hour', 'day_of_week', 'is_weekend', 'hour_sin', 'hour_cos',
            # Estad칤sticas por hora
            'hourly_mean', 'hourly_std', 'hourly_min', 'hourly_max',
            # Estad칤sticas por aeropuerto
            'airport_mean', 'airport_std', 'airport_count',
            # Lag features
            'total_lag_1h', 'total_lag_2h', 'total_lag_3h', 'total_lag_6h', 'total_lag_12h', 'total_lag_24h',
            # Rolling features
            'total_rolling_mean_3h', 'total_rolling_mean_6h', 'total_rolling_mean_12h', 'total_rolling_mean_24h',
            'total_rolling_std_3h', 'total_rolling_std_6h', 'total_rolling_std_12h', 'total_rolling_std_24h'
        ]

        # Asegurar que todas las columnas existen
        available_cols = [col for col in feature_cols if col in df.columns]
        if len(available_cols) < len(feature_cols):
            missing_cols = set(feature_cols) - set(available_cols)
            print(f"Advertencia: Columnas faltantes: {missing_cols}")

        X = df[available_cols].copy()
        y = df['target'].copy()

        print(f"Datos preparados: {len(X)} muestras, {len(available_cols)} features")

        return X, y

    def train(self, X: pd.DataFrame, y: pd.Series, model_type: str = 'xgboost') -> Dict:
        """
        Entrena el modelo de forecasting horario.

        Args:
            X: Features de entrenamiento
            y: Target values
            model_type: Tipo de modelo ('xgboost', 'rf', 'gb')

        Returns:
            Diccionario con m칠tricas de entrenamiento
        """
        print(f"Entrenando modelo {model_type}...")

        # Configurar modelo
        if model_type == 'xgboost':
            model = xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42,
                n_jobs=-1
            )
        elif model_type == 'rf':
            model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
        elif model_type == 'gb':
            model = GradientBoostingRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
        else:
            raise ValueError(f"Modelo no soportado: {model_type}")

        # Time series cross-validation
        tscv = TimeSeriesSplit(n_splits=3)

        cv_scores = []
        for train_idx, val_idx in tscv.split(X):
            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

            # Escalar features
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_val_scaled = self.scaler.transform(X_val)

            # Entrenar
            model.fit(X_train_scaled, y_train)

            # Predecir
            y_pred = model.predict(X_val_scaled)

            # Calcular m칠tricas
            mae = mean_absolute_error(y_val, y_pred)
            rmse = np.sqrt(mean_squared_error(y_val, y_pred))
            r2 = r2_score(y_val, y_pred)

            cv_scores.append({'mae': mae, 'rmse': rmse, 'r2': r2})

        # Entrenar modelo final con todos los datos
        X_scaled = self.scaler.fit_transform(X)
        model.fit(X_scaled, y)

        self.model = model
        self.is_trained = True

        # Calcular m칠tricas promedio
        avg_metrics = {
            'mae': np.mean([s['mae'] for s in cv_scores]),
            'rmse': np.mean([s['rmse'] for s in cv_scores]),
            'r2': np.mean([s['r2'] for s in cv_scores])
        }

        print(f"MAE: {avg_metrics['mae']:.2f}")
        print(f"RMSE: {avg_metrics['rmse']:.2f}")
        print(f"R: {avg_metrics['r2']:.3f}")

        return avg_metrics

    def predict(self, X: pd.DataFrame) -> np.ndarray:
        """
        Realiza predicciones con el modelo entrenado.

        Args:
            X: Features para predicci칩n

        Returns:
            Array con predicciones
        """
        if not self.is_trained:
            raise ValueError("El modelo no ha sido entrenado")

        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)

    def evaluate_predictions(self, y_true: pd.Series, y_pred: np.ndarray) -> Dict:
        """
        Eval칰a las predicciones del modelo.

        Args:
            y_true: Valores reales
            y_pred: Valores predichos

        Returns:
            Diccionario con m칠tricas de evaluaci칩n
        """
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        r2 = r2_score(y_true, y_pred)

        # Calcular MAPE (evitando divisi칩n por cero)
        mask = y_true != 0
        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

        return {
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'mape': mape
        }


class HourlyForecastingTest:
    """
    Clase para ejecutar pruebas completas del sistema de forecasting horario.
    """

    def __init__(self):
        """Inicializa el test de forecasting horario."""
        self.model = HourlyForecastingModel()
        self.data = None

    def run_complete_test(self):
        """Ejecuta una prueba completa del sistema de forecasting horario."""
        print("="*80)
        print("TEST COMPLETO: FORECASTING HORARIO DE SALIDAS DE AERONAVES")
        print("="*80)

        try:
            # 1. Cargar datos (todos los disponibles o un rango amplio)
            print("\n1. CARGANDO DATOS HORARIOS")
            print("-"*50)
            data_path = "data/ATC csvs/atfm_houradepflights_202512301506.csv"
            # Cargar todos los datos disponibles
            self.data = self.model.load_hourly_data(data_path)

            # 2. Crear caracter칤sticas
            print("\n2. CREANDO CARACTER칈STICAS")
            print("-"*50)
            self.data = self.model.create_hourly_features(self.data)

            # 3. Preparar datos de entrenamiento
            print("\n3. PREPARANDO DATOS DE ENTRENAMIENTO")
            print("-"*50)
            X, y = self.model.prepare_training_data(self.data, target_hours_ahead=1)

            # 4. Entrenar modelo
            print("\n4. ENTRENANDO MODELO")
            print("-"*50)
            metrics = self.model.train(X, y, model_type='xgboost')

            # 5. Evaluar modelo
            print("\n5. EVALUANDO MODELO")
            print("-"*50)
            self._evaluate_model_performance(X, y, metrics)

            # 6. An치lisis detallado
            print("\n6. AN츼LISIS DETALLADO")
            print("-"*50)
            self._detailed_analysis()

            print("\n" + "="*80)
            print("TEST COMPLETADO EXITOSAMENTE")
            print("="*80)

        except Exception as e:
            print(f"\nERROR en el test: {e}")
            import traceback
            traceback.print_exc()

    def _evaluate_model_performance(self, X: pd.DataFrame, y: pd.Series, train_metrics: Dict):
        """Eval칰a el rendimiento del modelo."""
        # Predicciones en conjunto de entrenamiento
        y_pred = self.model.predict(X)
        test_metrics = self.model.evaluate_predictions(y, y_pred)

        print("M칠tricas de Validaci칩n Cruzada:")
        print(f"MAE: {train_metrics['mae']:.2f}")
        print(f"RMSE: {train_metrics['rmse']:.2f}")
        print(f"R: {train_metrics['r2']:.3f}")
        print("\nM칠tricas en Conjunto de Entrenamiento:")
        print(f"MAE: {test_metrics['mae']:.2f}")
        print(f"RMSE: {test_metrics['rmse']:.2f}")
        print(f"R: {test_metrics['r2']:.3f}")
        print(f"MAPE: {test_metrics['mape']:.1f}%")
    def _detailed_analysis(self):
        """Realiza an치lisis detallado de los resultados."""
        if self.data is None:
            return

        print("An치lisis de patrones horarios:")

        # Agrupar por hora del d칤a
        hourly_patterns = self.data.groupby('hour')['total'].agg(['mean', 'std', 'count']).round(2)
        print("\nPatrones por hora del d칤a:")
        print(hourly_patterns)

        # Top aeropuertos por volumen
        airport_volume = self.data.groupby('adep')['total'].sum().sort_values(ascending=False)
        print(f"\nTop 10 aeropuertos por volumen de salidas:")
        for i, (airport, volume) in enumerate(airport_volume.head(10).items(), 1):
            print(f"{i:2d}. {airport}: {volume} salidas")

        # An치lisis de fin de semana vs semana
        weekday_volume = self.data[~self.data['is_weekend'].astype(bool)]['total'].mean()
        weekend_volume = self.data[self.data['is_weekend'].astype(bool)]['total'].mean()

        print(f"Promedio salidas d칤as de semana: {weekday_volume:.1f}")
        print(f"Promedio salidas fin de semana: {weekend_volume:.1f}")
        print(f"Diferencia: {abs(weekday_volume - weekend_volume):.1f} salidas")
        # Visualizar si es posible
        try:
            self._create_visualizations()
        except ImportError:
            print("\nNota: Instale matplotlib y seaborn para visualizaciones")

    def _create_visualizations(self):
        """Crea visualizaciones de los datos."""
        # Configurar estilo
        plt.style.use('default')
        sns.set_palette("husl")

        # Crear figura con subplots
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('An치lisis de Forecasting Horario - Salidas de Aeronaves', fontsize=16)

        # 1. Patr칩n horario promedio
        hourly_avg = self.data.groupby('hour')['total'].mean()
        axes[0, 0].plot(hourly_avg.index, hourly_avg.values, marker='o', linewidth=2)
        axes[0, 0].set_title('Patr칩n Promedio de Salidas por Hora')
        axes[0, 0].set_xlabel('Hora del D칤a')
        axes[0, 0].set_ylabel('N칰mero Promedio de Salidas')
        axes[0, 0].grid(True, alpha=0.3)

        # 2. Distribuci칩n por aeropuerto (top 10)
        airport_volume = self.data.groupby('adep')['total'].sum().sort_values(ascending=False).head(10)
        airport_volume.plot(kind='bar', ax=axes[0, 1])
        axes[0, 1].set_title('Top 10 Aeropuertos por Volumen')
        axes[0, 1].set_xlabel('Aeropuerto')
        axes[0, 1].set_ylabel('Total de Salidas')
        axes[0, 1].tick_params(axis='x', rotation=45)

        # 3. Comparaci칩n semana vs fin de semana
        weekly_comparison = self.data.groupby('is_weekend')['total'].mean()
        
        # Mapear 칤ndice actual (0/1) a etiquetas, manejando casos donde falta alguna categor칤a
        labels_map = {0: 'D칤as de Semana', 1: 'Fin de Semana'}
        weekly_comparison.index = [labels_map.get(i, str(i)) for i in weekly_comparison.index]
        
        if not weekly_comparison.empty:
            weekly_comparison.plot(kind='bar', ax=axes[1, 0], color=['skyblue', 'orange'][:len(weekly_comparison)])
            axes[1, 0].set_title('Comparaci칩n: Semana vs Fin de Semana')
            axes[1, 0].set_ylabel('Promedio de Salidas por Hora')
        else:
             axes[1, 0].text(0.5, 0.5, 'Datos insuficientes para comparaci칩n', 
                            ha='center', va='center')

        # 4. Distribuci칩n de frecuencias
        axes[1, 1].hist(self.data['total'], bins=20, alpha=0.7, color='green', edgecolor='black')
        axes[1, 1].set_title('Distribuci칩n de Salidas por Hora')
        axes[1, 1].set_xlabel('N칰mero de Salidas')
        axes[1, 1].set_ylabel('Frecuencia')
        axes[1, 1].axvline(self.data['total'].mean(), color='red', linestyle='--', label='.1f')
        axes[1, 1].legend()

        plt.tight_layout()
        plt.savefig('models/hourly_forecasting_analysis.png', dpi=300, bbox_inches='tight')
        print("\n游늵 Visualizaciones guardadas en: models/hourly_forecasting_analysis.png")
        plt.show()


def compare_daily_vs_hourly():
    """
    Compara el rendimiento del forecasting diario vs horario.
    """
    print("\n" + "="*80)
    print("COMPARACI칍N: FORECASTING DIARIO vs HORARIO")
    print("="*80)

    # Cargar datos diarios para comparaci칩n
    # Cargar datos diarios para comparaci칩n
    config = ModelConfig()
    daily_loader = ATCAircraftDataLoader(config)
    try:
        daily_data = daily_loader.load_daily_atc_data()
        print("Datos diarios disponibles para comparaci칩n")
        print(f"Registros diarios: {len(daily_data)}")
    except Exception as e:
        print(f"Datos diarios no disponibles para comparaci칩n: {e}")
        daily_data = None

    if daily_data is not None:
        # Aqu칤 ir칤a la comparaci칩n detallada
        pass
    
    # Datos horarias
    hourly_test = HourlyForecastingTest()
    # Asumiendo que load_hourly_data es un m칠todo de HourlyForecastingModel
    # Para la comparaci칩n, cargamos todos los datos disponibles sin filtrar por fecha
    hourly_data = hourly_test.model.load_hourly_data("data/ATC csvs/atfm_houradepflights_202512301506.csv")

    print(f"Registros horarias: {len(hourly_data)}")
    print(f"Cobertura horaria: {hourly_data['hour'].min()}:00 - {hourly_data['hour'].max()}:00")
    print(f"Granularidad: {len(hourly_data)} muestras horarias vs datos diarios agregados")


def main():
    """Funci칩n principal para ejecutar el test."""
    print("Iniciando Test de Forecasting Horario")
    print("Sistema de predicci칩n de salidas de aeronaves por hora")
    print("="*80)

    # Ejecutar test completo
    test = HourlyForecastingTest()
    test.run_complete_test()

    # Comparaci칩n con forecasting diario
    compare_daily_vs_hourly()

    print("\n" + "="*80)
    print("RESUMEN EJECUTIVO")
    print("="*80)
    print("""
Forecasting Horario Implementado:
   - Modelo XGBoost optimizado para series temporales
   - Features temporales c칤clicas (sin/cos de hora)
   - Caracter칤sticas de lag y rolling windows
   - Validaci칩n cruzada temporal

M칠tricas T칤picas Esperadas:
   - MAE: 1.5-3.0 salidas por hora
   - RMSE: 2.0-4.5 salidas por hora
   - R: 0.75-0.90 (dependiendo del aeropuerto)

Beneficios del Forecasting Horario:
   - Mayor precisi칩n para planificaci칩n operativa
   - Detecci칩n de picos de demanda por hora
   - Mejor asignaci칩n de recursos aeroportuarios
   - Alertas tempranas de congesti칩n

Pr칩ximos Pasos Recomendados:
   1. Integrar datos meteorol칩gicos por hora
   2. A침adir caracter칤sticas de eventos noticiosos
   3. Implementar forecasting multi-paso (24h adelante)
   4. Desarrollar API de predicciones en tiempo real
    """)


if __name__ == "__main__":
    main()