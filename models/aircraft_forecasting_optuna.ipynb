{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aircraft_forecasting_optuna.py\n",
    "\n",
    "# Importaciones básicas\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Añadir el directorio padre al path\n",
    "sys.path.append(str(Path().cwd().parent))\n",
    "\n",
    "# Importar bibliotecas de análisis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Importar módulos personalizados\n",
    "from models import (\n",
    "    ModelConfig,\n",
    "    ATCAircraftDataLoader,\n",
    "    AircraftDataPreprocessor,\n",
    "    AircraftFeatureEngineer,\n",
    "    ARIMAModel,\n",
    "    ProphetModel,\n",
    "    RandomForestModel,\n",
    "    LSTMModel,\n",
    "    EnsembleModel,\n",
    "    AircraftForecaster\n",
    ")\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuración\n",
    "config = ModelConfig()\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(forecast_horizon=7):\n",
    "    \"\"\"Carga y prepara los datos para el entrenamiento.\"\"\"\n",
    "    logger.info(\"Cargando y preparando datos...\")\n",
    "    \n",
    "    # 1. Cargar datos\n",
    "    data_loader = ATCAircraftDataLoader(config)\n",
    "    df = data_loader.get_training_data('daily_atc')\n",
    "    \n",
    "    # 2. Preprocesar datos\n",
    "    preprocessor = AircraftDataPreprocessor(config)\n",
    "    df_processed = preprocessor.preprocess_daily_data(df)\n",
    "    \n",
    "    # 3. Ingeniería de características\n",
    "    feature_engineer = AircraftFeatureEngineer(config)\n",
    "    df_featured = feature_engineer.create_features(df_processed)\n",
    "    df_featured = feature_engineer.create_lagged_target(\n",
    "        df_featured, \n",
    "        forecast_horizon=forecast_horizon\n",
    "    )\n",
    "    \n",
    "    # 4. Preparar datos para modelado\n",
    "    X, y = feature_engineer.select_features_for_model(df_featured)\n",
    "    \n",
    "    logger.info(f\"Datos preparados: {len(X)} muestras, {len(X.columns)} características\")\n",
    "    \n",
    "    return X, y, df_featured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6eb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, model_type='random_forest'):\n",
    "    \"\"\"\n",
    "    Función objetivo para la optimización con Optuna.\n",
    "    \n",
    "    Args:\n",
    "        trial: Objeto de prueba de Optuna\n",
    "        X: Características de entrenamiento\n",
    "        y: Variable objetivo\n",
    "        model_type: Tipo de modelo a optimizar ('random_forest', 'prophet', 'lstm', 'arima')\n",
    "        \n",
    "    Returns:\n",
    "        Error de validación (MAE) a minimizar\n",
    "    \"\"\"\n",
    "    # Crear una copia de la configuración\n",
    "    trial_config = ModelConfig()\n",
    "    \n",
    "    if model_type == 'random_forest':\n",
    "        # Espacio de búsqueda para Random Forest\n",
    "        trial_config.models['random_forest'] = {\n",
    "            'n_estimators': trial.suggest_int('rf_n_estimators', 50, 500, step=50),\n",
    "            'max_depth': trial.suggest_int('rf_max_depth', 3, 30),\n",
    "            'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_categorical('rf_max_features', ['sqrt', 'log2', None]),\n",
    "            'bootstrap': trial.suggest_categorical('rf_bootstrap', [True, False]),\n",
    "            'random_state': RANDOM_STATE\n",
    "        }\n",
    "        \n",
    "        model = RandomForestModel(trial_config)\n",
    "        \n",
    "    elif model_type == 'prophet':\n",
    "        # Espacio de búsqueda para Prophet\n",
    "        trial_config.models['prophet'] = {\n",
    "            'yearly_seasonality': trial.suggest_categorical('prophet_yearly', [True, False]),\n",
    "            'weekly_seasonality': trial.suggest_categorical('prophet_weekly', [True, False]),\n",
    "            'daily_seasonality': trial.suggest_categorical('prophet_daily', [True, False]),\n",
    "            'changepoint_prior_scale': trial.suggest_float('prophet_changepoint_prior_scale', 0.001, 0.5, log=True),\n",
    "            'seasonality_prior_scale': trial.suggest_float('prophet_seasonality_prior_scale', 0.1, 10, log=True),\n",
    "            'seasonality_mode': trial.suggest_categorical('prophet_seasonality_mode', ['additive', 'multiplicative']),\n",
    "            'changepoint_range': trial.suggest_float('prophet_changepoint_range', 0.8, 0.95),\n",
    "            'n_changepoints': trial.suggest_int('prophet_n_changepoints', 10, 50, step=5)\n",
    "        }\n",
    "        \n",
    "        model = ProphetModel(trial_config)\n",
    "        \n",
    "    elif model_type == 'lstm':\n",
    "        # Espacio de búsqueda para LSTM\n",
    "        trial_config.models['lstm'] = {\n",
    "            'sequence_length': trial.suggest_int('lstm_sequence_length', 7, 30, step=7),\n",
    "            'hidden_units': trial.suggest_int('lstm_hidden_units', 32, 256, step=32),\n",
    "            'dropout_rate': trial.suggest_float('lstm_dropout', 0.1, 0.5, step=0.1),\n",
    "            'epochs': trial.suggest_int('lstm_epochs', 50, 200, step=50),\n",
    "            'batch_size': trial.suggest_categorical('lstm_batch_size', [16, 32, 64]),\n",
    "            'learning_rate': trial.suggest_float('lstm_learning_rate', 1e-4, 1e-2, log=True),\n",
    "            'optimizer': trial.suggest_categorical('lstm_optimizer', ['adam', 'rmsprop']),\n",
    "            'num_layers': trial.suggest_int('lstm_num_layers', 1, 3)\n",
    "        }\n",
    "        \n",
    "        model = LSTMModel(trial_config)\n",
    "        \n",
    "    elif model_type == 'arima':\n",
    "        # Espacio de búsqueda para ARIMA\n",
    "        p = trial.suggest_int('arima_p', 0, 5)\n",
    "        d = trial.suggest_int('arima_d', 0, 2)\n",
    "        q = trial.suggest_int('arima_q', 0, 5)\n",
    "        P = trial.suggest_int('arima_P', 0, 3)\n",
    "        D = trial.suggest_int('arima_D', 0, 2)\n",
    "        Q = trial.suggest_int('arima_Q', 0, 3)\n",
    "        s = 7  # Estacionalidad semanal\n",
    "        \n",
    "        trial_config.models['arima'] = {\n",
    "            'order': (p, d, q),\n",
    "            'seasonal_order': (P, D, Q, s)\n",
    "        }\n",
    "        \n",
    "        model = ARIMAModel(trial_config)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Tipo de modelo no soportado: {model_type}\")\n",
    "    \n",
    "    # Validación cruzada temporal\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # Ajustar el modelo\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predecir\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        scores.append(mae)\n",
    "    \n",
    "    # Devolver el MAE promedio\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31fb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(X, y, model_type='random_forest', n_trials=50):\n",
    "    \"\"\"\n",
    "    Optimiza los hiperparámetros usando Optuna.\n",
    "    \n",
    "    Args:\n",
    "        X: Características\n",
    "        y: Variable objetivo\n",
    "        model_type: Tipo de modelo a optimizar\n",
    "        n_trials: Número de pruebas a realizar\n",
    "        \n",
    "    Returns:\n",
    "        study: Objeto de estudio de Optuna\n",
    "    \"\"\"\n",
    "    # Crear estudio\n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        sampler=TPESampler(seed=RANDOM_STATE),\n",
    "        study_name=f'aircraft_forecasting_{model_type}'\n",
    "    )\n",
    "    \n",
    "    # Función objetivo parcial\n",
    "    def objective_wrapper(trial):\n",
    "        return objective(trial, X, y, model_type)\n",
    "    \n",
    "    # Optimizar\n",
    "    logger.info(f\"Iniciando optimización para {model_type} con {n_trials} pruebas...\")\n",
    "    study.optimize(objective_wrapper, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    logger.info(\"Mejores parámetros encontrados:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        logger.info(f\"  {key}: {value}\")\n",
    "    \n",
    "    logger.info(f\"Mejor MAE: {study.best_value:.4f}\")\n",
    "    \n",
    "    return study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ae28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Función principal para ejecutar la optimización.\"\"\"\n",
    "# Cargar y preparar datos\n",
    "X, y, _ = load_and_prepare_data(forecast_horizon=7)\n",
    "\n",
    "# Modelos a optimizar\n",
    "models_to_optimize = ['random_forest', 'prophet', 'lstm', 'arima']\n",
    "\n",
    "# Diccionario para almacenar los estudios\n",
    "studies = {}\n",
    "\n",
    "# Optimizar cada modelo\n",
    "for model_type in models_to_optimize:\n",
    "    try:\n",
    "        study = optimize_hyperparameters(\n",
    "            X, y, \n",
    "            model_type=model_type,\n",
    "            n_trials=50  # Ajustar según sea necesario\n",
    "        )\n",
    "        studies[model_type] = study\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error optimizando {model_type}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"==== Optimización completada ====\", studies)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
