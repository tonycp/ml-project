{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7d6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aircraft_forecasting_optuna.py\n",
    "\n",
    "# Importaciones básicas\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Añadir el directorio padre al path\n",
    "sys.path.append(str(Path().cwd().parent))\n",
    "\n",
    "# Importar bibliotecas de análisis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_slice\n",
    ")\n",
    "\n",
    "# Importar módulos personalizados\n",
    "from models import (\n",
    "    ModelConfig,\n",
    "    ATCAircraftDataLoader,\n",
    "    AircraftDataPreprocessor,\n",
    "    AircraftFeatureEngineer,\n",
    "    ARIMAModel,\n",
    "    ProphetModel,\n",
    "    RandomForestModel,\n",
    "    LSTMModel,\n",
    "    EnsembleModel,\n",
    "    AircraftForecaster,\n",
    "    MultiModalDataLoader,\n",
    "    NewsDataLoader,\n",
    "    WeatherDataLoader,\n",
    "    XGBoostModel\n",
    ")\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuración\n",
    "config = ModelConfig()\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb97601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(config, forecast_horizon=1):\n",
    "    \"\"\"Carga y prepara los datos para el entrenamiento.\"\"\"\n",
    "    logger.info(\"Cargando y preparando datos...\")\n",
    "    \n",
    "    # 1. Cargar datos\n",
    "    data_loader = ATCAircraftDataLoader(config)\n",
    "    df = data_loader.load_daily_atc_data()\n",
    "    \n",
    "    acids = data_loader.load_daily_acids_data(use_one_hot=True)\n",
    "    df = pd.merge(df, acids, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    news_loader = NewsDataLoader(config)\n",
    "    news = news_loader.load_news_events(feature_type='one_hot')\n",
    "    df = pd.merge(df, news, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    weather_loader = WeatherDataLoader(config)\n",
    "    weather = weather_loader.load_weather_data(\n",
    "        start_date=df.index.min().strftime('%Y-%m-%d'),\n",
    "        end_date=df.index.max().strftime('%Y-%m-%d')\n",
    "    )\n",
    "    df = pd.merge(df, weather, left_index=True, right_index=True, how='left')\n",
    " \n",
    "    # 2. Preprocesar datos\n",
    "    preprocessor = AircraftDataPreprocessor(config)\n",
    "    df_processed = preprocessor.preprocess_daily_data(df)\n",
    "    \n",
    "    # 3. Ingeniería de características\n",
    "    feature_engineer = AircraftFeatureEngineer(config)\n",
    "    df_featured = feature_engineer.create_features(df_processed)\n",
    "    df_featured = feature_engineer.create_lagged_target(\n",
    "        df_featured, \n",
    "        forecast_horizon=forecast_horizon\n",
    "    )\n",
    "    \n",
    "    # 4. Preparar datos para modelado\n",
    "    X, y = feature_engineer.select_features_for_model(df_featured)\n",
    "    \n",
    "    logger.info(f\"Datos preparados: {len(X)} muestras, {len(X.columns)} características\")\n",
    "    \n",
    "    return X, y, df_featured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506e1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_hourly_data(config, forecast_horizon=1):\n",
    "    \"\"\"Carga y prepara los datos para el entrenamiento.\"\"\"\n",
    "    logger.info(\"Cargando y preparando datos...\")\n",
    "    \n",
    "    # 1. Cargar datos\n",
    "    data_loader = ATCAircraftDataLoader(config)\n",
    "    df = data_loader.load_hourly_atc_data()\n",
    "        \n",
    "    # acids = data_loader.load_hourly_acids_data(use_one_hot=True)\n",
    "    # df = pd.merge(df, acids, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # weather_loader = WeatherDataLoader(config)\n",
    "    # weather = weather_loader.load_hourly_weather_data(\n",
    "    #     start_date=df.index.min().strftime('%Y-%m-%d'),\n",
    "    #     end_date=df.index.max().strftime('%Y-%m-%d'),\n",
    "    #     use_median=False\n",
    "    # )\n",
    "    # df = pd.merge(df, weather, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # news_loader = NewsDataLoader(config)\n",
    "    # hourly_news = news_loader.load_hourly_news_events(\n",
    "    #     start_date=df.index.min().strftime('%Y-%m-%d'),\n",
    "    #     end_date=df.index.max().strftime('%Y-%m-%d'),\n",
    "    #     feature_type='aggregated'\n",
    "    # )\n",
    "    # df = pd.merge(df, hourly_news, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # 2. Preprocesar datos\n",
    "    preprocessor = AircraftDataPreprocessor(config)\n",
    "    df_processed = preprocessor.preprocess_hourly_data(df)\n",
    "    \n",
    "    # 3. Ingeniería de características\n",
    "    feature_engineer = AircraftFeatureEngineer(config)\n",
    "    df_featured = feature_engineer.create_features(df_processed)\n",
    "    df_featured = feature_engineer.create_lagged_target(\n",
    "        df_featured, \n",
    "        forecast_horizon=forecast_horizon\n",
    "    )\n",
    "    \n",
    "    # 4. Preparar datos para modelado\n",
    "    X, y = feature_engineer.select_features_for_model(df_featured)\n",
    "    \n",
    "    logger.info(f\"Datos preparados: {len(X)} muestras, {len(X.columns)} características\")\n",
    "    \n",
    "    return X, y, df_featured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1d09f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data_multimodal(config, forecast_horizon=1):\n",
    "    \"\"\"\n",
    "    Carga y preprocesa los datos de múltiples fuentes.\n",
    "    \"\"\"\n",
    "    logger.info(\"Iniciando carga de datos...\")\n",
    "    \n",
    "    # 1. Cargar datos usando MultiModalDataLoader\n",
    "    logger.info(\"Cargando datos A = TC, clima y noticias...\")\n",
    "    multimodal_loader = MultiModalDataLoader(config)\n",
    "    \n",
    "    # Cargar datos combinados\n",
    "    combined_data = multimodal_loader.load_multimodal_data(\n",
    "        data_type='daily_atc',\n",
    "        use_one_hot=True,\n",
    "        include_weather=True,\n",
    "        include_news=False\n",
    "    )\n",
    "    \n",
    "    # 2. Preprocesar datos\n",
    "    preprocessor = AircraftDataPreprocessor(config)\n",
    "    processed_data = preprocessor.preprocess_daily_data(combined_data)\n",
    "    \n",
    "    # 3. Crear características adicionales\n",
    "    feature_engineer = AircraftFeatureEngineer(config)\n",
    "    featured_data = feature_engineer.create_features(processed_data)\n",
    "    featured_data = feature_engineer.create_lagged_target(featured_data, forecast_horizon=1)\n",
    "\n",
    "    # 4. Seleccionar features para modelado\n",
    "    X, y = feature_engineer.select_features_for_model(featured_data)\n",
    "    \n",
    "    logger.info(f\"Datos preparados para modelado: {len(X)} registros, {len(X.columns)} características\")\n",
    "    \n",
    "    return X, y, featured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6eb60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, algorithm_list=['random_forest', 'prophet', 'lstm', 'arima', 'xgboost']):\n",
    "    \"\"\"\n",
    "    Función objetivo para la optimización con Optuna.\n",
    "    \n",
    "    Args:\n",
    "        trial: Objeto de prueba de Optuna\n",
    "        X: Características de entrenamiento\n",
    "        y: Variable objetivo\n",
    "        \n",
    "    Returns:\n",
    "        Error de validación (MAE) a minimizar\n",
    "    \"\"\"\n",
    "    # Selección del modelo\n",
    "    algorithm = trial.suggest_categorical('algorithm', algorithm_list)\n",
    "\n",
    "    # Crear una copia de la configuración\n",
    "    trial_config = ModelConfig()\n",
    "\n",
    "    if algorithm == 'random_forest':\n",
    "        # Espacio de búsqueda para Random Forest\n",
    "        trial_config.models['random_forest'] = {\n",
    "            'n_estimators': trial.suggest_int('rf_n_estimators', 50, 500, step=50),\n",
    "            'max_depth': trial.suggest_int('rf_max_depth', 3, 30),\n",
    "            'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_categorical('rf_max_features', ['sqrt', 'log2', None]),\n",
    "            'bootstrap': trial.suggest_categorical('rf_bootstrap', [True, False]),\n",
    "            'random_state': RANDOM_STATE\n",
    "        }\n",
    "        \n",
    "        model = RandomForestModel(trial_config)\n",
    "        \n",
    "    elif algorithm == 'prophet':\n",
    "        # Espacio de búsqueda para Prophet\n",
    "        trial_config.models['prophet'] = {\n",
    "            'yearly_seasonality': trial.suggest_categorical('prophet_yearly', [True, False]),\n",
    "            'weekly_seasonality': trial.suggest_categorical('prophet_weekly', [True, False]),\n",
    "            'daily_seasonality': trial.suggest_categorical('prophet_daily', [True, False]),\n",
    "            'changepoint_prior_scale': trial.suggest_float('prophet_changepoint_prior_scale', 0.001, 0.5, log=True),\n",
    "            'seasonality_prior_scale': trial.suggest_float('prophet_seasonality_prior_scale', 0.1, 10, log=True),\n",
    "            'seasonality_mode': trial.suggest_categorical('prophet_seasonality_mode', ['additive', 'multiplicative']),\n",
    "            'changepoint_range': trial.suggest_float('prophet_changepoint_range', 0.8, 0.95),\n",
    "            'n_changepoints': trial.suggest_int('prophet_n_changepoints', 10, 50, step=5)\n",
    "        }\n",
    "        \n",
    "        model = ProphetModel(trial_config)\n",
    "        \n",
    "    elif algorithm == 'lstm':\n",
    "        # Espacio de búsqueda para LSTM\n",
    "        trial_config.models['lstm'] = {\n",
    "            'sequence_length': trial.suggest_int('lstm_sequence_length', 7, 30, step=7),\n",
    "            'hidden_units': trial.suggest_int('lstm_hidden_units', 32, 256, step=32),\n",
    "            'dropout_rate': trial.suggest_float('lstm_dropout', 0.1, 0.5, step=0.1),\n",
    "            'epochs': trial.suggest_int('lstm_epochs', 50, 200, step=50),\n",
    "            'batch_size': trial.suggest_categorical('lstm_batch_size', [16, 32, 64]),\n",
    "            'learning_rate': trial.suggest_float('lstm_learning_rate', 1e-4, 1e-2, log=True),\n",
    "            'optimizer': trial.suggest_categorical('lstm_optimizer', ['adam', 'rmsprop']),\n",
    "            'num_layers': trial.suggest_int('lstm_num_layers', 1, 3)\n",
    "        }\n",
    "        \n",
    "        model = LSTMModel(trial_config)\n",
    "        \n",
    "    elif algorithm == 'arima':\n",
    "        # Espacio de búsqueda para ARIMA\n",
    "        p = trial.suggest_int('arima_p', 0, 5)\n",
    "        d = trial.suggest_int('arima_d', 0, 2)\n",
    "        q = trial.suggest_int('arima_q', 0, 5)\n",
    "        P = trial.suggest_int('arima_P', 0, 3)\n",
    "        D = trial.suggest_int('arima_D', 0, 2)\n",
    "        Q = trial.suggest_int('arima_Q', 0, 3)\n",
    "        s = 7  # Estacionalidad semanal\n",
    "        \n",
    "        trial_config.models['arima'] = {\n",
    "            'order': (p, d, q),\n",
    "            'seasonal_order': (P, D, Q, s)\n",
    "        }\n",
    "        \n",
    "        model = ARIMAModel(trial_config)\n",
    "\n",
    "    elif algorithm == 'xgboost':\n",
    "        # Espacio de búsqueda para XGBoost\n",
    "        trial_config.models['xgboost'] = {\n",
    "            'n_estimators': trial.suggest_int('xgb_n_estimators', 50, 500, step=50),\n",
    "            'max_depth': trial.suggest_int('xgb_max_depth', 3, 15),\n",
    "            'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('xgb_subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.6, 1.0),\n",
    "            'min_child_weight': trial.suggest_int('xgb_min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('xgb_gamma', 0, 5),\n",
    "            'reg_alpha': trial.suggest_float('xgb_reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('xgb_reg_lambda', 0, 1),\n",
    "            'random_state': RANDOM_STATE,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "        model = XGBoostModel(trial_config)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Tipo de modelo no soportado: {algorithm}\")\n",
    "    \n",
    "    # Validación cruzada temporal\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # Ajustar el modelo\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predecir\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Alinear predicciones con el target y filtrar valores no finitos\n",
    "        y_pred = np.asarray(y_pred).ravel()\n",
    "\n",
    "        if len(y_pred) != len(y_val):\n",
    "            min_len = min(len(y_pred), len(y_val))\n",
    "            y_pred = y_pred[-min_len:]\n",
    "            y_val_aligned = y_val.iloc[-min_len:]\n",
    "        else:\n",
    "            y_val_aligned = y_val\n",
    "\n",
    "        valid_mask = np.isfinite(y_pred)\n",
    "        if not valid_mask.any():\n",
    "            raise ValueError(\"Predicciones no válidas: todas son NaN o infinitas\")\n",
    "\n",
    "        y_pred = y_pred[valid_mask]\n",
    "        y_val_aligned = y_val_aligned.iloc[np.where(valid_mask)[0]]\n",
    "\n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(y_val_aligned, y_pred)\n",
    "        scores.append(mae)\n",
    "    \n",
    "    # Devolver el MAE promedio\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6382cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_emsemble(trial, X, y, algorithm_list=['ensemble', 'random_forest', 'prophet', 'lstm', 'arima']):\n",
    "    \"\"\"\n",
    "    Función objetivo para la optimización con Optuna.\n",
    "    \n",
    "    Args:\n",
    "        trial: Objeto de prueba de Optuna\n",
    "        X: Características de entrenamiento\n",
    "        y: Variable objetivo\n",
    "        \n",
    "    Returns:\n",
    "        Error de validación (MAE) a minimizar\n",
    "    \"\"\"\n",
    "    # Selección del modelo\n",
    "    algorithm = trial.suggest_categorical('algorithm', algorithm_list)\n",
    "\n",
    "    # Crear una copia de la configuración\n",
    "    trial_config = ModelConfig()\n",
    "    \n",
    "    # Configuración común para los modelos base\n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 50, 500, step=25),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 3, 30),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('rf_min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('rf_max_features', ['sqrt', 'log2', None]),\n",
    "        'bootstrap': trial.suggest_categorical('rf_bootstrap', [True, False]),\n",
    "        'random_state': RANDOM_STATE\n",
    "    }\n",
    "    \n",
    "    prophet_params = {\n",
    "        'yearly_seasonality': trial.suggest_categorical('prophet_yearly', [True, False]),\n",
    "        'weekly_seasonality': trial.suggest_categorical('prophet_weekly', [True, False]),\n",
    "        'daily_seasonality': trial.suggest_categorical('prophet_daily', [True, False]),\n",
    "        'changepoint_prior_scale': trial.suggest_float('prophet_changepoint_prior_scale', 0.001, 0.5, log=True),\n",
    "        'seasonality_prior_scale': trial.suggest_float('prophet_seasonality_prior_scale', 0.1, 10, log=True),\n",
    "        'seasonality_mode': trial.suggest_categorical('prophet_seasonality_mode', ['additive', 'multiplicative']),\n",
    "        'changepoint_range': trial.suggest_float('prophet_changepoint_range', 0.8, 0.95),\n",
    "        'n_changepoints': trial.suggest_int('prophet_n_changepoints', 10, 50, step=5)\n",
    "    }\n",
    "    \n",
    "    lstm_params = {\n",
    "        'sequence_length': trial.suggest_int('lstm_sequence_length', 7, 30, step=7),\n",
    "        'hidden_units': trial.suggest_int('lstm_hidden_units', 32, 256, step=32),\n",
    "        'dropout_rate': trial.suggest_float('lstm_dropout', 0.1, 0.5, step=0.1),\n",
    "        'epochs': trial.suggest_int('lstm_epochs', 50, 200, step=50),\n",
    "        'batch_size': trial.suggest_categorical('lstm_batch_size', [16, 32, 64]),\n",
    "        'learning_rate': trial.suggest_float('lstm_learning_rate', 1e-4, 1e-2, log=True),\n",
    "        'optimizer': trial.suggest_categorical('lstm_optimizer', ['adam', 'rmsprop']),\n",
    "        'num_layers': trial.suggest_int('lstm_num_layers', 1, 3)\n",
    "    }\n",
    "    \n",
    "    # Parámetros ARIMA\n",
    "    p = trial.suggest_int('arima_p', 0, 5)\n",
    "    d = trial.suggest_int('arima_d', 0, 2)\n",
    "    q = trial.suggest_int('arima_q', 0, 5)\n",
    "    P = trial.suggest_int('arima_P', 0, 3)\n",
    "    D = trial.suggest_int('arima_D', 0, 2)\n",
    "    Q = trial.suggest_int('arima_Q', 0, 3)\n",
    "    s = 7  # Estacionalidad semanal\n",
    "\n",
    "    if algorithm == 'random_forest':\n",
    "        trial_config.models['random_forest'] = rf_params\n",
    "        model = RandomForestModel(trial_config)\n",
    "        \n",
    "    elif algorithm == 'prophet':\n",
    "        trial_config.models['prophet'] = prophet_params\n",
    "        model = ProphetModel(trial_config)\n",
    "        \n",
    "    elif algorithm == 'lstm':\n",
    "        trial_config.models['lstm'] = lstm_params\n",
    "        model = LSTMModel(trial_config)\n",
    "        \n",
    "    elif algorithm == 'arima':\n",
    "        trial_config.models['arima'] = {\n",
    "            'order': (p, d, q),\n",
    "            'seasonal_order': (P, D, Q, s)\n",
    "        }\n",
    "        model = ARIMAModel(trial_config)\n",
    "        \n",
    "    elif algorithm == 'ensemble':\n",
    "        # Crear configuración para el ensemble\n",
    "        trial_config = ModelConfig()\n",
    "        \n",
    "        # Definir espacio de búsqueda para los pesos\n",
    "        weights = {\n",
    "            'arima': trial.suggest_float('ensemble_weight_arima', 0, 1),\n",
    "            'prophet': trial.suggest_float('ensemble_weight_prophet', 0, 1),\n",
    "            'random_forest': trial.suggest_float('ensemble_weight_rf', 0, 1),\n",
    "            'lstm': trial.suggest_float('ensemble_weight_lstm', 0, 1)\n",
    "        }\n",
    "        \n",
    "        # Normalizar pesos para que sumen 1\n",
    "        total = sum(weights.values())\n",
    "        weights = {k: v/total for k, v in weights.items()}\n",
    "        \n",
    "        # Configurar pesos en la configuración\n",
    "        trial_config.models['ensemble'] = {'weights': weights}\n",
    "        \n",
    "        # Configurar parámetros de los modelos base\n",
    "        trial_config.models['random_forest'] = rf_params\n",
    "        trial_config.models['prophet'] = prophet_params\n",
    "        trial_config.models['lstm'] = lstm_params\n",
    "        trial_config.models['arima'] = {\n",
    "            'order': (p, d, q),\n",
    "            'seasonal_order': (P, D, Q, s)\n",
    "        }\n",
    "        \n",
    "        # Crear el ensemble y añadir modelos base\n",
    "        ensemble = EnsembleModel(trial_config)\n",
    "        ensemble.add_model(ARIMAModel(trial_config), weight=weights['arima'])\n",
    "        ensemble.add_model(ProphetModel(trial_config), weight=weights['prophet'])\n",
    "        ensemble.add_model(RandomForestModel(trial_config), weight=weights['random_forest'])\n",
    "        ensemble.add_model(LSTMModel(trial_config), weight=weights['lstm'])\n",
    "        \n",
    "        model = ensemble\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Tipo de modelo no soportado: {algorithm}\")\n",
    "    \n",
    "    # Validación cruzada temporal\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # Ajustar el modelo\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predecir\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Alinear predicciones con el target y filtrar valores no finitos\n",
    "        y_pred = np.asarray(y_pred).ravel()\n",
    "\n",
    "        if len(y_pred) != len(y_val):\n",
    "            min_len = min(len(y_pred), len(y_val))\n",
    "            y_pred = y_pred[-min_len:]\n",
    "            y_val_aligned = y_val.iloc[-min_len:]\n",
    "        else:\n",
    "            y_val_aligned = y_val\n",
    "\n",
    "        valid_mask = np.isfinite(y_pred)\n",
    "        if not valid_mask.any():\n",
    "            raise ValueError(\"Predicciones no válidas: todas son NaN o infinitas\")\n",
    "\n",
    "        y_pred = y_pred[valid_mask]\n",
    "        y_val_aligned = y_val_aligned.iloc[np.where(valid_mask)[0]]\n",
    "\n",
    "        # Calcular métricas\n",
    "        mae = mean_absolute_error(y_val_aligned, y_pred)\n",
    "        scores.append(mae)\n",
    "    \n",
    "    # Devolver el MAE promedio\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d31fb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(X, y, objective_fuc, algorithm_list=None, n_trials=50):\n",
    "    \"\"\"\n",
    "    Optimiza los hiperparámetros usando Optuna.\n",
    "    \n",
    "    Args:\n",
    "        X: Características\n",
    "        y: Variable objetivo\n",
    "        n_trials: Número de pruebas a realizar\n",
    "        \n",
    "    Returns:\n",
    "        study: Objeto de estudio de Optuna\n",
    "    \"\"\"\n",
    "    # Crear o cargar estudio con almacenamiento persistente\n",
    "    try:\n",
    "        # Intentar cargar un estudio existente\n",
    "        study = optuna.create_study(\n",
    "            study_name=study_name,\n",
    "            storage=storage_name,\n",
    "            load_if_exists=True,\n",
    "            direction='minimize',\n",
    "            sampler=TPESampler(seed=RANDOM_STATE)\n",
    "        )\n",
    "        logger.info(f\"Estudio cargado. Número de trials existentes: {len(study.trials)}\")\n",
    "    except Exception as e:\n",
    "        # Si no existe, crear uno nuevo\n",
    "        study = optuna.create_study(\n",
    "            study_name=study_name,\n",
    "            storage=storage_name,\n",
    "            direction='minimize',\n",
    "            sampler=TPESampler(seed=RANDOM_STATE)\n",
    "        )\n",
    "        logger.info(\"Nuevo estudio creado\")\n",
    "    \n",
    "    # Función objetivo parcial\n",
    "    def objective_wrapper(trial):\n",
    "        if algorithm_list:\n",
    "            return objective_fuc(trial, X, y, algorithm_list)\n",
    "        else:\n",
    "            return objective_fuc(trial, X, y)\n",
    "        \n",
    "    \n",
    "    # Calcular cuántos trials nuevos necesitamos\n",
    "    remaining_trials = max(0, n_trials - len(study.trials))\n",
    "    \n",
    "    if remaining_trials > 0:\n",
    "        logger.info(f\"Iniciando optimización con {remaining_trials} pruebas nuevas...\")\n",
    "        study.optimize(objective_wrapper, n_trials=remaining_trials, show_progress_bar=True)\n",
    "    else:\n",
    "        logger.info(f\"Ya se han completado {len(study.trials)} trials. No se necesitan más pruebas.\")\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    logger.info(\"\\nResumen de la optimización:\")\n",
    "    logger.info(f\"Número total de trials: {len(study.trials)}\")\n",
    "    logger.info(f\"Mejor valor (MAE): {study.best_value:.4f}\")\n",
    "    logger.info(\"Mejores parámetros encontrados:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        logger.info(f\"  {key}: {value}\")\n",
    "    \n",
    "    return study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c602fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de almacenamiento para Optuna\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Crear directorio para almacenamiento si no existe\n",
    "storage_dir = Path(\"optuna_storage\")\n",
    "storage_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c857c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el almacenamiento\n",
    "storage_name = f\"sqlite:///{storage_dir}/aircraft_forecasting_hourly.db\"\n",
    "study_name = \"aircraft_forecasting_study\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "139ae28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:33:59,861 - __main__ - INFO - Cargando y preparando datos...\n",
      "2026-01-12 00:33:59,862 - models.data_loader - INFO - Cargando datos horarios ATC desde: data/ATC csvs/atc_houratcopsummary_202512301506.csv\n",
      "2026-01-12 00:33:59,938 - models.data_loader - INFO - Datos horarios cargados: 16910 registros, columnas: ['arrivals', 'departures', 'overflights', 'nationals', 'unknown', 'total', 'fpp']\n",
      "2026-01-12 00:33:59,939 - models.preprocessing - INFO - Iniciando preprocesamiento de datos horarios\n",
      "2026-01-12 00:33:59,949 - models.preprocessing - INFO - Frecuencia horaria asegurada: 26753 horas (original: 16910)\n",
      "2026-01-12 00:33:59,956 - models.preprocessing - INFO - Datos suavizados: 260 valores ajustados\n",
      "2026-01-12 00:33:59,958 - models.preprocessing - INFO - Validación de integridad: OK\n",
      "2026-01-12 00:33:59,958 - models.preprocessing - INFO - Preprocesamiento horario completado: 26753 registros\n",
      "2026-01-12 00:33:59,959 - models.features - INFO - Iniciando creación de características\n",
      "2026-01-12 00:33:59,967 - models.features - INFO - Features de lag añadidas: [1, 7, 14, 30]\n",
      "2026-01-12 00:33:59,974 - models.features - INFO - Features móviles añadidas: ventanas [7, 14, 30]\n",
      "2026-01-12 00:33:59,980 - models.features - INFO - Features estacionales añadidas\n",
      "2026-01-12 00:33:59,982 - models.features - INFO - Features de días festivos añadidas\n",
      "2026-01-12 00:33:59,985 - models.features - INFO - Ajuste COVID: no aplica a este rango de fechas\n",
      "2026-01-12 00:33:59,995 - models.features - INFO - Características creadas: 39 columnas totales\n",
      "2026-01-12 00:34:00,000 - models.features - INFO - Target creado con horizonte 1: 26752 registros válidos\n",
      "2026-01-12 00:34:00,013 - models.features - INFO - Features seleccionadas para regression: 38 features, 26752 targets\n",
      "2026-01-12 00:34:00,014 - __main__ - INFO - Datos preparados: 26752 muestras, 38 características\n",
      "[I 2026-01-12 00:34:00,117] A new study created in RDB with name: aircraft_forecasting_study\n",
      "2026-01-12 00:34:00,120 - __main__ - INFO - Estudio cargado. Número de trials existentes: 0\n",
      "2026-01-12 00:34:00,121 - __main__ - INFO - Iniciando optimización con 25 pruebas nuevas...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d3f835ae164b18b922900b649ed7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:34:00,184 - models.model - INFO - Entrenando LSTM con sequence_length=21\n",
      "2026-01-12 00:34:49,074 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:34:49,075 - models.model - INFO - Pérdida final: 0.0064, MAE: 0.0488\n",
      "2026-01-12 00:34:49,075 - models.model - INFO - Pérdida de validación: 0.0002, MAE de validación: 0.0107\n",
      "2026-01-12 00:34:49,814 - models.model - INFO - Entrenando LSTM con sequence_length=21\n",
      "2026-01-12 00:35:55,949 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:35:55,949 - models.model - INFO - Pérdida final: 0.0042, MAE: 0.0370\n",
      "2026-01-12 00:35:55,950 - models.model - INFO - Pérdida de validación: 0.0087, MAE de validación: 0.0478\n",
      "2026-01-12 00:35:56,702 - models.model - INFO - Entrenando LSTM con sequence_length=21\n",
      "2026-01-12 00:38:29,957 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:38:29,957 - models.model - INFO - Pérdida final: 0.0026, MAE: 0.0280\n",
      "2026-01-12 00:38:29,958 - models.model - INFO - Pérdida de validación: 0.0000, MAE de validación: 0.0052\n",
      "2026-01-12 00:38:30,732 - models.model - INFO - Entrenando LSTM con sequence_length=21\n",
      "2026-01-12 00:40:41,536 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:40:41,536 - models.model - INFO - Pérdida final: 0.0034, MAE: 0.0322\n",
      "2026-01-12 00:40:41,537 - models.model - INFO - Pérdida de validación: 0.0066, MAE de validación: 0.0560\n",
      "2026-01-12 00:40:42,301 - models.model - INFO - Entrenando LSTM con sequence_length=21\n",
      "2026-01-12 00:43:32,048 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:43:32,049 - models.model - INFO - Pérdida final: 0.0029, MAE: 0.0315\n",
      "2026-01-12 00:43:32,049 - models.model - INFO - Pérdida de validación: 0.0028, MAE de validación: 0.0380\n",
      "2026-01-12 00:43:32,954 - models.model - INFO - Entrenando XGBoost con 300 estimadores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:43:32,813] Trial 0 finished with value: 8.313167823826934 and parameters: {'algorithm': 'lstm', 'lstm_sequence_length': 21, 'lstm_hidden_units': 64, 'lstm_dropout': 0.1, 'lstm_epochs': 50, 'lstm_batch_size': 16, 'lstm_learning_rate': 0.00010994335574766199, 'lstm_optimizer': 'adam', 'lstm_num_layers': 1}. Best is trial 0 with value: 8.313167823826934.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:43:33,804 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:33,819 - models.model - INFO - Entrenando XGBoost con 300 estimadores\n",
      "2026-01-12 00:43:34,538 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:34,554 - models.model - INFO - Entrenando XGBoost con 300 estimadores\n",
      "2026-01-12 00:43:35,408 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:35,426 - models.model - INFO - Entrenando XGBoost con 300 estimadores\n",
      "2026-01-12 00:43:36,392 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:36,410 - models.model - INFO - Entrenando XGBoost con 300 estimadores\n",
      "2026-01-12 00:43:37,419 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:37,555 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:43:37,480] Trial 1 finished with value: 5.714568409784779 and parameters: {'algorithm': 'xgboost', 'xgb_n_estimators': 300, 'xgb_max_depth': 8, 'xgb_learning_rate': 0.02692655251486473, 'xgb_subsample': 0.8447411578889518, 'xgb_colsample_bytree': 0.6557975442608167, 'xgb_min_child_weight': 3, 'xgb_gamma': 1.8318092164684585, 'xgb_reg_alpha': 0.45606998421703593, 'xgb_reg_lambda': 0.7851759613930136}. Best is trial 1 with value: 5.714568409784779.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:43:37,757 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:37,768 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n",
      "2026-01-12 00:43:38,057 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:38,092 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n",
      "2026-01-12 00:43:38,455 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:38,467 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n",
      "2026-01-12 00:43:38,923 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:38,936 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n",
      "2026-01-12 00:43:39,466 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:43:39,530 - models.model - INFO - Entrenando Random Forest con 250 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:43:39,485] Trial 2 finished with value: 8.661545247049464 and parameters: {'algorithm': 'xgboost', 'xgb_n_estimators': 50, 'xgb_max_depth': 10, 'xgb_learning_rate': 0.0178601378893971, 'xgb_subsample': 0.6260206371941118, 'xgb_colsample_bytree': 0.9795542149013333, 'xgb_min_child_weight': 10, 'xgb_gamma': 4.041986740582305, 'xgb_reg_alpha': 0.3046137691733707, 'xgb_reg_lambda': 0.09767211400638387}. Best is trial 1 with value: 5.714568409784779.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:43:40,081 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:43:40,128 - models.model - INFO - Entrenando Random Forest con 250 árboles\n",
      "2026-01-12 00:43:41,052 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:43:41,093 - models.model - INFO - Entrenando Random Forest con 250 árboles\n",
      "2026-01-12 00:43:42,461 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:43:42,507 - models.model - INFO - Entrenando Random Forest con 250 árboles\n",
      "2026-01-12 00:43:44,356 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:43:44,402 - models.model - INFO - Entrenando Random Forest con 250 árboles\n",
      "2026-01-12 00:43:46,690 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:43:46,787 - models.model - INFO - Entrenando Random Forest con 450 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:43:46,741] Trial 3 finished with value: 6.9814690773949435 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 250, 'rf_max_depth': 3, 'rf_min_samples_split': 19, 'rf_min_samples_leaf': 3, 'rf_max_features': 'sqrt', 'rf_bootstrap': True}. Best is trial 1 with value: 5.714568409784779.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:44:01,423 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:44:01,536 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 00:44:30,380 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:44:30,493 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 00:45:19,688 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:45:19,849 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 00:46:31,175 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:46:31,346 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 00:48:04,550 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:48:04,848 - models.model - INFO - Entrenando Random Forest con 300 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:48:04,791] Trial 4 finished with value: 4.988475388286027 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 450, 'rf_max_depth': 19, 'rf_min_samples_split': 19, 'rf_min_samples_leaf': 1, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 4 with value: 4.988475388286027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:48:06,275 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:48:06,333 - models.model - INFO - Entrenando Random Forest con 300 árboles\n",
      "2026-01-12 00:48:08,999 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:48:09,052 - models.model - INFO - Entrenando Random Forest con 300 árboles\n",
      "2026-01-12 00:48:13,299 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:48:13,365 - models.model - INFO - Entrenando Random Forest con 300 árboles\n",
      "2026-01-12 00:48:19,184 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:48:19,249 - models.model - INFO - Entrenando Random Forest con 300 árboles\n",
      "2026-01-12 00:48:26,641 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:48:26,824 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n",
      "2026-01-12 00:48:26,931 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:26,941 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:48:26,756] Trial 5 finished with value: 5.213959796967589 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 300, 'rf_max_depth': 6, 'rf_min_samples_split': 17, 'rf_min_samples_leaf': 1, 'rf_max_features': 'sqrt', 'rf_bootstrap': False}. Best is trial 4 with value: 4.988475388286027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:48:27,090 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:27,103 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n",
      "2026-01-12 00:48:27,251 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:27,263 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n",
      "2026-01-12 00:48:27,534 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:27,548 - models.model - INFO - Entrenando XGBoost con 50 estimadores\n",
      "2026-01-12 00:48:27,738 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:27,811 - models.model - INFO - Entrenando XGBoost con 250 estimadores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:48:27,755] Trial 6 finished with value: 9.673773504621918 and parameters: {'algorithm': 'xgboost', 'xgb_n_estimators': 50, 'xgb_max_depth': 7, 'xgb_learning_rate': 0.014830392684568025, 'xgb_subsample': 0.9452413703502374, 'xgb_colsample_bytree': 0.8493192507310232, 'xgb_min_child_weight': 4, 'xgb_gamma': 0.3177917514301182, 'xgb_reg_alpha': 0.3109823217156622, 'xgb_reg_lambda': 0.32518332202674705}. Best is trial 4 with value: 4.988475388286027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:48:27,971 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:27,984 - models.model - INFO - Entrenando XGBoost con 250 estimadores\n",
      "2026-01-12 00:48:28,307 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:28,327 - models.model - INFO - Entrenando XGBoost con 250 estimadores\n",
      "2026-01-12 00:48:28,583 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:28,596 - models.model - INFO - Entrenando XGBoost con 250 estimadores\n",
      "2026-01-12 00:48:28,808 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:28,822 - models.model - INFO - Entrenando XGBoost con 250 estimadores\n",
      "2026-01-12 00:48:29,053 - models.model - INFO - XGBoost entrenado exitosamente\n",
      "2026-01-12 00:48:29,125 - models.model - INFO - Entrenando LSTM con sequence_length=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:48:29,071] Trial 7 finished with value: 6.649897489079156 and parameters: {'algorithm': 'xgboost', 'xgb_n_estimators': 250, 'xgb_max_depth': 4, 'xgb_learning_rate': 0.1131225105716033, 'xgb_subsample': 0.9043140194467589, 'xgb_colsample_bytree': 0.8245108790277985, 'xgb_min_child_weight': 8, 'xgb_gamma': 2.4689779818219537, 'xgb_reg_alpha': 0.5227328293819941, 'xgb_reg_lambda': 0.42754101835854963}. Best is trial 4 with value: 4.988475388286027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:48:46,896 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:48:46,897 - models.model - INFO - Pérdida final: 0.0081, MAE: 0.0573\n",
      "2026-01-12 00:48:46,897 - models.model - INFO - Pérdida de validación: 0.0003, MAE de validación: 0.0154\n",
      "2026-01-12 00:48:47,646 - models.model - INFO - Entrenando LSTM con sequence_length=21\n",
      "2026-01-12 00:49:20,570 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:49:20,571 - models.model - INFO - Pérdida final: 0.0046, MAE: 0.0404\n",
      "2026-01-12 00:49:20,571 - models.model - INFO - Pérdida de validación: 0.0082, MAE de validación: 0.0572\n",
      "2026-01-12 00:49:21,336 - models.model - INFO - Entrenando LSTM con sequence_length=21\n",
      "2026-01-12 00:49:51,276 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:49:51,277 - models.model - INFO - Pérdida final: 0.0048, MAE: 0.0381\n",
      "2026-01-12 00:49:51,277 - models.model - INFO - Pérdida de validación: 0.0002, MAE de validación: 0.0148\n",
      "2026-01-12 00:49:52,040 - models.model - INFO - Entrenando LSTM con sequence_length=21\n",
      "2026-01-12 00:50:52,803 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:50:52,804 - models.model - INFO - Pérdida final: 0.0040, MAE: 0.0366\n",
      "2026-01-12 00:50:52,805 - models.model - INFO - Pérdida de validación: 0.0086, MAE de validación: 0.0667\n",
      "2026-01-12 00:50:53,611 - models.model - INFO - Entrenando LSTM con sequence_length=21\n",
      "2026-01-12 00:53:20,197 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 00:53:20,198 - models.model - INFO - Pérdida final: 0.0029, MAE: 0.0338\n",
      "2026-01-12 00:53:20,198 - models.model - INFO - Pérdida de validación: 0.0036, MAE de validación: 0.0441\n",
      "2026-01-12 00:53:21,109 - models.model - INFO - Entrenando Random Forest con 450 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:53:21,051] Trial 8 finished with value: 9.786140024955174 and parameters: {'algorithm': 'lstm', 'lstm_sequence_length': 21, 'lstm_hidden_units': 96, 'lstm_dropout': 0.30000000000000004, 'lstm_epochs': 200, 'lstm_batch_size': 64, 'lstm_learning_rate': 0.00028681134821030097, 'lstm_optimizer': 'rmsprop', 'lstm_num_layers': 1}. Best is trial 4 with value: 4.988475388286027.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:53:33,782 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:53:33,894 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 00:53:59,423 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:53:59,535 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 00:54:44,470 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:54:44,628 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 00:55:51,576 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:55:51,744 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 00:57:18,116 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:57:18,377 - models.model - INFO - Entrenando Random Forest con 500 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 00:57:18,321] Trial 9 finished with value: 4.522450110880933 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 450, 'rf_max_depth': 25, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 9, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 9 with value: 4.522450110880933.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 00:57:32,045 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:57:32,164 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 00:57:59,823 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:57:59,941 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 00:58:48,892 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 00:58:49,060 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:00:02,392 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:00:02,574 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:01:37,587 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:01:37,869 - models.model - INFO - Entrenando Random Forest con 500 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:01:37,811] Trial 10 finished with value: 4.521147066570125 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 500, 'rf_max_depth': 30, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 10, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:01:51,531 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:01:51,646 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:02:19,301 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:02:19,418 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:03:08,362 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:03:08,533 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:04:21,944 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:04:22,125 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:05:57,064 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:05:57,378 - models.model - INFO - Entrenando Random Forest con 500 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:05:57,319] Trial 11 finished with value: 4.521147066570125 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 500, 'rf_max_depth': 30, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 10, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:06:11,043 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:06:11,160 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:06:38,827 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:06:38,945 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:07:27,904 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:07:28,073 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:08:41,517 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:08:41,698 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:10:16,768 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:10:17,039 - models.model - INFO - Entrenando Random Forest con 350 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:10:16,984] Trial 12 finished with value: 4.521147066570125 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 500, 'rf_max_depth': 30, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 10, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:10:18,684 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:10:18,770 - models.model - INFO - Entrenando Random Forest con 350 árboles\n",
      "2026-01-12 01:10:21,837 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:10:21,922 - models.model - INFO - Entrenando Random Forest con 350 árboles\n",
      "2026-01-12 01:10:27,087 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:10:27,215 - models.model - INFO - Entrenando Random Forest con 350 árboles\n",
      "2026-01-12 01:10:34,642 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:10:34,789 - models.model - INFO - Entrenando Random Forest con 350 árboles\n",
      "2026-01-12 01:10:44,505 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:10:44,723 - models.model - INFO - Entrenando Random Forest con 50 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:10:44,671] Trial 13 finished with value: 4.803919190975462 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 350, 'rf_max_depth': 29, 'rf_min_samples_split': 8, 'rf_min_samples_leaf': 7, 'rf_max_features': 'log2', 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:10:47,096 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:10:47,112 - models.model - INFO - Entrenando Random Forest con 50 árboles\n",
      "2026-01-12 01:10:52,021 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:10:52,040 - models.model - INFO - Entrenando Random Forest con 50 árboles\n",
      "2026-01-12 01:11:00,739 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:11:00,762 - models.model - INFO - Entrenando Random Forest con 50 árboles\n",
      "2026-01-12 01:11:13,040 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:11:13,064 - models.model - INFO - Entrenando Random Forest con 50 árboles\n",
      "2026-01-12 01:11:29,283 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:11:29,419 - models.model - INFO - Entrenando Random Forest con 500 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:11:29,354] Trial 14 finished with value: 5.997546768099672 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 50, 'rf_max_depth': 23, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 7, 'rf_max_features': None, 'rf_bootstrap': False}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:11:41,821 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:11:41,932 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:12:06,719 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:12:06,822 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:12:48,230 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:12:48,377 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:13:47,059 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:13:47,212 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:15:03,422 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:15:03,655 - models.model - INFO - Entrenando LSTM con sequence_length=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:15:03,594] Trial 15 finished with value: 4.557816228842376 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 500, 'rf_max_depth': 11, 'rf_min_samples_split': 12, 'rf_min_samples_leaf': 10, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:15:15,352 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:15:15,353 - models.model - INFO - Pérdida final: 0.0078, MAE: 0.0561\n",
      "2026-01-12 01:15:15,353 - models.model - INFO - Pérdida de validación: 0.0020, MAE de validación: 0.0446\n",
      "2026-01-12 01:15:15,908 - models.model - INFO - Entrenando LSTM con sequence_length=7\n",
      "2026-01-12 01:15:49,316 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:15:49,317 - models.model - INFO - Pérdida final: 0.0058, MAE: 0.0484\n",
      "2026-01-12 01:15:49,317 - models.model - INFO - Pérdida de validación: 0.0086, MAE de validación: 0.0631\n",
      "2026-01-12 01:15:49,858 - models.model - INFO - Entrenando LSTM con sequence_length=7\n",
      "2026-01-12 01:16:05,685 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:16:05,686 - models.model - INFO - Pérdida final: 0.0050, MAE: 0.0424\n",
      "2026-01-12 01:16:05,686 - models.model - INFO - Pérdida de validación: 0.0002, MAE de validación: 0.0147\n",
      "2026-01-12 01:16:06,231 - models.model - INFO - Entrenando LSTM con sequence_length=7\n",
      "2026-01-12 01:16:55,547 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:16:55,548 - models.model - INFO - Pérdida final: 0.0267, MAE: 0.1156\n",
      "2026-01-12 01:16:55,548 - models.model - INFO - Pérdida de validación: 0.0580, MAE de validación: 0.1738\n",
      "2026-01-12 01:16:56,096 - models.model - INFO - Entrenando LSTM con sequence_length=7\n",
      "2026-01-12 01:17:59,969 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:17:59,969 - models.model - INFO - Pérdida final: 0.0044, MAE: 0.0434\n",
      "2026-01-12 01:17:59,970 - models.model - INFO - Pérdida de validación: 0.0038, MAE de validación: 0.0496\n",
      "2026-01-12 01:18:00,650 - models.model - INFO - Entrenando Random Forest con 400 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:18:00,588] Trial 16 finished with value: 7.607729422874504 and parameters: {'algorithm': 'lstm', 'lstm_sequence_length': 7, 'lstm_hidden_units': 224, 'lstm_dropout': 0.5, 'lstm_epochs': 200, 'lstm_batch_size': 32, 'lstm_learning_rate': 0.007501054462493079, 'lstm_optimizer': 'adam', 'lstm_num_layers': 3}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:18:02,513 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:18:02,625 - models.model - INFO - Entrenando Random Forest con 400 árboles\n",
      "2026-01-12 01:18:06,043 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:18:06,143 - models.model - INFO - Entrenando Random Forest con 400 árboles\n",
      "2026-01-12 01:18:11,994 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:18:12,136 - models.model - INFO - Entrenando Random Forest con 400 árboles\n",
      "2026-01-12 01:18:20,503 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:18:20,656 - models.model - INFO - Entrenando Random Forest con 400 árboles\n",
      "2026-01-12 01:18:31,724 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:18:31,962 - models.model - INFO - Entrenando Random Forest con 150 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:18:31,911] Trial 17 finished with value: 4.790252958574224 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 400, 'rf_max_depth': 24, 'rf_min_samples_split': 7, 'rf_min_samples_leaf': 8, 'rf_max_features': 'log2', 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:18:39,412 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:18:39,450 - models.model - INFO - Entrenando Random Forest con 150 árboles\n",
      "2026-01-12 01:18:54,465 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:18:54,509 - models.model - INFO - Entrenando Random Forest con 150 árboles\n",
      "2026-01-12 01:19:19,936 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:19:19,988 - models.model - INFO - Entrenando Random Forest con 150 árboles\n",
      "2026-01-12 01:19:55,725 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:19:55,787 - models.model - INFO - Entrenando Random Forest con 150 árboles\n",
      "2026-01-12 01:20:43,128 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:20:43,274 - models.model - INFO - Entrenando LSTM con sequence_length=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:20:43,212] Trial 18 finished with value: 6.012979689203393 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 150, 'rf_max_depth': 17, 'rf_min_samples_split': 12, 'rf_min_samples_leaf': 4, 'rf_max_features': None, 'rf_bootstrap': False}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:21:11,291 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:21:11,291 - models.model - INFO - Pérdida final: 0.0034, MAE: 0.0364\n",
      "2026-01-12 01:21:11,292 - models.model - INFO - Pérdida de validación: 0.0008, MAE de validación: 0.0280\n",
      "2026-01-12 01:21:11,863 - models.model - INFO - Entrenando LSTM con sequence_length=7\n",
      "2026-01-12 01:21:44,300 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:21:44,301 - models.model - INFO - Pérdida final: 0.0028, MAE: 0.0315\n",
      "2026-01-12 01:21:44,301 - models.model - INFO - Pérdida de validación: 0.0061, MAE de validación: 0.0413\n",
      "2026-01-12 01:21:44,859 - models.model - INFO - Entrenando LSTM con sequence_length=7\n",
      "2026-01-12 01:22:12,547 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:22:12,548 - models.model - INFO - Pérdida final: 0.0027, MAE: 0.0291\n",
      "2026-01-12 01:22:12,548 - models.model - INFO - Pérdida de validación: 0.0001, MAE de validación: 0.0085\n",
      "2026-01-12 01:22:13,091 - models.model - INFO - Entrenando LSTM con sequence_length=7\n",
      "2026-01-12 01:24:18,439 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:24:18,439 - models.model - INFO - Pérdida final: 0.0021, MAE: 0.0269\n",
      "2026-01-12 01:24:18,440 - models.model - INFO - Pérdida de validación: 0.0059, MAE de validación: 0.0529\n",
      "2026-01-12 01:24:18,972 - models.model - INFO - Entrenando LSTM con sequence_length=7\n",
      "2026-01-12 01:25:16,826 - models.model - INFO - LSTM entrenado exitosamente\n",
      "2026-01-12 01:25:16,826 - models.model - INFO - Pérdida final: 0.0025, MAE: 0.0301\n",
      "2026-01-12 01:25:16,827 - models.model - INFO - Pérdida de validación: 0.0027, MAE de validación: 0.0377\n",
      "2026-01-12 01:25:17,421 - models.model - INFO - Entrenando Random Forest con 400 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:25:17,368] Trial 19 finished with value: 6.804689651749231 and parameters: {'algorithm': 'lstm', 'lstm_sequence_length': 7, 'lstm_hidden_units': 256, 'lstm_dropout': 0.1, 'lstm_epochs': 50, 'lstm_batch_size': 16, 'lstm_learning_rate': 0.003917034330357435, 'lstm_optimizer': 'rmsprop', 'lstm_num_layers': 3}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:25:29,578 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:25:29,680 - models.model - INFO - Entrenando Random Forest con 400 árboles\n",
      "2026-01-12 01:25:54,015 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:25:54,122 - models.model - INFO - Entrenando Random Forest con 400 árboles\n",
      "2026-01-12 01:26:36,795 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:26:36,954 - models.model - INFO - Entrenando Random Forest con 400 árboles\n",
      "2026-01-12 01:27:40,020 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:27:40,188 - models.model - INFO - Entrenando Random Forest con 400 árboles\n",
      "2026-01-12 01:29:02,096 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:29:02,351 - models.model - INFO - Entrenando Random Forest con 500 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:29:02,300] Trial 20 finished with value: 4.565018969647722 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 400, 'rf_max_depth': 27, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 6, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:29:16,099 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:29:16,217 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:29:43,944 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:29:44,060 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:30:33,062 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:30:33,229 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:31:46,066 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:31:46,247 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:33:20,879 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:33:21,193 - models.model - INFO - Entrenando Random Forest con 500 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:33:21,132] Trial 21 finished with value: 4.521239447379675 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 500, 'rf_max_depth': 29, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 10, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:33:34,926 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:33:35,041 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:34:02,670 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:34:02,788 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:34:51,732 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:34:51,899 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:36:04,710 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:36:04,890 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:37:39,374 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:37:39,658 - models.model - INFO - Entrenando Random Forest con 450 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:37:39,607] Trial 22 finished with value: 4.521239447379675 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 500, 'rf_max_depth': 29, 'rf_min_samples_split': 2, 'rf_min_samples_leaf': 10, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:37:52,297 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:37:52,404 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 01:38:17,812 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:38:17,924 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 01:39:02,873 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:39:03,032 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 01:40:09,743 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:40:09,910 - models.model - INFO - Entrenando Random Forest con 450 árboles\n",
      "2026-01-12 01:41:36,369 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:41:36,622 - models.model - INFO - Entrenando Random Forest con 500 árboles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:41:36,571] Trial 23 finished with value: 4.522041648588024 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 450, 'rf_max_depth': 30, 'rf_min_samples_split': 5, 'rf_min_samples_leaf': 9, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 01:41:50,908 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:41:51,027 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:42:19,824 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:42:19,945 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:43:10,459 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:43:10,637 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:44:25,232 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:44:25,421 - models.model - INFO - Entrenando Random Forest con 500 árboles\n",
      "2026-01-12 01:46:03,169 - models.model - INFO - Random Forest entrenado exitosamente\n",
      "2026-01-12 01:46:03,438 - __main__ - INFO - \n",
      "Resumen de la optimización:\n",
      "2026-01-12 01:46:03,444 - __main__ - INFO - Número total de trials: 25\n",
      "2026-01-12 01:46:03,445 - __main__ - INFO - Mejor valor (MAE): 4.5211\n",
      "2026-01-12 01:46:03,445 - __main__ - INFO - Mejores parámetros encontrados:\n",
      "2026-01-12 01:46:03,446 - __main__ - INFO -   algorithm: random_forest\n",
      "2026-01-12 01:46:03,447 - __main__ - INFO -   rf_n_estimators: 500\n",
      "2026-01-12 01:46:03,447 - __main__ - INFO -   rf_max_depth: 30\n",
      "2026-01-12 01:46:03,447 - __main__ - INFO -   rf_min_samples_split: 2\n",
      "2026-01-12 01:46:03,447 - __main__ - INFO -   rf_min_samples_leaf: 10\n",
      "2026-01-12 01:46:03,448 - __main__ - INFO -   rf_max_features: None\n",
      "2026-01-12 01:46:03,448 - __main__ - INFO -   rf_bootstrap: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-01-12 01:46:03,435] Trial 24 finished with value: 4.538847024870694 and parameters: {'algorithm': 'random_forest', 'rf_n_estimators': 500, 'rf_max_depth': 23, 'rf_min_samples_split': 4, 'rf_min_samples_leaf': 8, 'rf_max_features': None, 'rf_bootstrap': True}. Best is trial 10 with value: 4.521147066570125.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Función principal para ejecutar la optimización.\"\"\"\n",
    "# Cargar y preparar datos\n",
    "X, y, _ = load_and_prepare_hourly_data(config,forecast_horizon=1)\n",
    "\n",
    "study = optimize_hyperparameters(X, y, objective, n_trials=25, algorithm_list=['random_forest', 'lstm', 'xgboost'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
